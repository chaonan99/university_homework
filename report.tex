\input{header}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%% Content %%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\tableofcontents
\clearpage

\begin{abstract}

\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%% Main %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[video to text introdution]
\section{Introduction}
The task of automatically describing videos containing
rich and open-domain activities poses an important challenges
for computer vision and machine learning research.
It also has a variety of practical applications.

\section{Related works}
\subsection{Sequence learning task}

\subsection{Image captioning}
Automatically generating a natural language description of an image, a problem known as image captioning, has recently received a lot of attention in Computer Vision. The problem is interesting not only because it has important practical applications, such as helping visually impaired people see, but also because it is regarded as a grand challenge for image understanding which is a core problem in Computer Vision.

\subsection{Video captioning}


\subsection{Attention}
Attention mechanism is a popular topic in deep learning these years. It is loosely based on human visual attention mechanism, as we tend to focus on a certain region with “high resolution” while perceiving the surrounding image in “low resolution”, and then adjust the focal point over time. Attention is successfully used in machine translation\cite{bahdanau2014neural}, image captioning\cite{xu2015show}, and video captioning\cite{venugopalan2014translating} tasks (these are the very first work using attention in their tasks).

\begin{figure}[htbp]
\centering
\includegraphics[width=11cm]{resources/logo.jpg}
\caption{No caption}
\label{fig:fullarm}
\end{figure}


\bibliography{reference}

\end{document}
